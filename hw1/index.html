<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
				max-width: 100%;
			}

			body {
				font-family: 'Inter', sans-serif;
				line-height: 1.6;
			}

			table {
				border-collapse: collapse;
				width: 100%;
				margin: 10px 0;
			}

			table.benchmark td, table.benchmark th {
				border: 1px solid #ddd;
				padding: 6px 10px;
				text-align: left;
			}

			table.benchmark th {
				background-color: #f5f5f5;
			}

			code {
				background-color: #f4f4f4;
				padding: 2px 5px;
				border-radius: 3px;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Name: Shuochen Hao</div>

		<br>

		<h2>Overview</h2>
		<p>
			In this project, I implemented a rasterizer that supports triangle rasterization, supersampling-based antialiasing, 2D transforms, barycentric coordinate interpolation, texture mapping with pixel sampling and level sampling (mipmaps), and anisotropic filtering.
		</p>
		<p>
			Key takeaways:
		</p>
		<ul>
			<li>Rasterization performance is heavily influenced by memory access patterns. Seemingly obvious optimizations (like pre-calculating constants or changing loop order) can actually hurt performance due to cache effects. Tiled traversal with tile size 8 achieved the best speedup (~1.8x over naive) by balancing computation savings with cache-friendly access.</li>
			<li>Antialiasing is fundamentally about trading computation/memory for visual quality. Supersampling is conceptually the simplest but most expensive; pixel-level bilinear sampling and mipmap-based level sampling offer better cost-quality tradeoffs.</li>
			<li>Anisotropic filtering addresses a real limitation of isotropic mipmaps: when a surface is viewed at an oblique angle, the footprint in texture space is elongated, and standard mipmaps over-blur in one direction. Sampling along the major axis at a finer mipmap level preserves detail where it matters.</li>
		</ul>

		<h2>Task 1: Drawing Single-Color Triangles</h2>

		<h3>Q1. Walk through how you rasterize triangles in your own words.</h3>
		<ul>
			<li>Step 1: Calculate the determinant of (x1-x0, y1-y0) and (x2-x0, y2-y0) and swap (x1, y1) and (x2, y2) to ensure the triangle is drawn counterclockwise.</li>
			<li>Step 2: Calculate the bounding box and clamp it to screen size.</li>
			<li>Step 3: Test a tile of pixels first. If the tile is fully inside/outside of the triangle, then skip the test of pixels in the tile. If not the case, test each pixel in the tile explicitly.</li>
			<li>Step 4: For each pixel in the tile, add offset (0.5, 0.5) to translate to center.</li>
			<li>Step 5: Use 3 line tests to test whether or not the pixel is in the triangle or on the edge (OpenGL top-left edge rules).</li>
		</ul>

		<h3>Q2. Explain how your algorithm is no worse than one that checks each sample within the bounding box of the triangle.</h3>
		<ul>
			<li>First, I test a tile of pixels first. If the tile is fully inside/outside of the triangle, then skip the test of pixels in the tile. If not the case, test each pixel in the tile explicitly. Using the tiled triangle traversal, I decrease the computation.</li>
			<li>Second, instead of testing pixels independently, I test pixels based on previous result: by utilizing the linear feature of line function, I degenerate the expensive multiplication into cheap addition.</li>
		</ul>

		<h3>Q3. Show a png screenshot of basic/test4.svg with the default viewing parameters and with the pixel inspector centered on an interesting part of the scene.</h3>
		<figure>
			<img src="./images/write_1_picture.png" style="width:70%"/>
			<figcaption>test4.svg - This part shows explicitly jaggies in the sharp edge of the purple triangle.</figcaption>
		</figure>

		<h3>Extra Credit: Special optimizations beyond simple bounding box triangle rasterization</h3>
		<p>The following statistic is based on running for 200 times and the first 100 results are excluded to fully warm up the cache.</p>
		<table class="benchmark">
			<tr><th>Version</th><th>Mean (ms)</th><th>Std (ms)</th><th>Notes</th></tr>
			<tr><td>V1: Naive</td><td>0.979</td><td>0.029</td><td>Baseline</td></tr>
			<tr><td>V2: Pre-calculate constants</td><td>1.037</td><td>0.025</td><td>Slower: compiler already did this; extra variables hurt cache</td></tr>
			<tr><td>V3: Exchange loop order (y-x)</td><td>1.219</td><td>0.025</td><td>Slower: original x-y order fits cache line better</td></tr>
			<tr><td>V4: Incremental traversal</td><td>0.801</td><td>0.024</td><td>Use addition instead of multiplication via linear property of edge functions</td></tr>
			<tr><td>V5: Tiled (tile=2)</td><td>1.238</td><td>0.048</td><td>Too small tile, overhead dominates</td></tr>
			<tr><td>V5: Tiled (tile=4)</td><td>0.643</td><td>0.034</td><td></td></tr>
			<tr><td>V5: Tiled (tile=8)</td><td>0.545</td><td>0.034</td><td>Best: ~1.8x speedup over naive</td></tr>
			<tr><td>V5: Tiled (tile=16)</td><td>0.640</td><td>0.038</td><td></td></tr>
			<tr><td>V5: Tiled (tile=32)</td><td>0.934</td><td>0.030</td><td>Larger tiles reduce benefit of skipping</td></tr>
		</table>
		<p><b>Tiled traversal (tile=8):</b> First test a block of pixels. If the block is fully inside the triangle, simply rasterize all pixels without per-pixel edge tests. If the block is fully outside the triangle, skip it entirely. Otherwise, fall back to incremental traversal within the block.</p>
		<p><b>Why some "optimizations" slow down:</b> Pre-calculating constants and exchanging loop order both hurt cache hit rate. The compiler already performs constant folding, and x-major loop order naturally aligns with row-major memory layout.</p>

		<h2>Task 2: Antialiasing by Supersampling</h2>

		<h3>Q1. Walk through your supersampling algorithm and data structures.</h3>
		<ul>
			<li>Step 1: Divide one original pixel into sqrt(sample_rate) &times; sqrt(sample_rate) subpixels.</li>
			<li>Step 2: Evaluate each subpixel as a normal pixel to decide whether or not to rasterize it.</li>
			<li>Step 3: Write the rasterize results of subpixels into the sample buffer.</li>
			<li>Step 4: Sum up the colors of all subpixels belonging to one pixel then divide by sample rate to get the final color.</li>
		</ul>

		<h3>Q2. Why is supersampling useful?</h3>
		<p>It takes the average of color across multiple sub-pixel samples within one pixel, which smooths out jagged edges (aliasing artifacts) along triangle boundaries.</p>

		<h3>Q3. What modifications did you make to the rasterization pipeline in the process?</h3>
		<p>For triangles: evaluate subpixels then take the average color of subpixels, as described in Q1.</p>
		<p>For points and lines: fill up all subpixels in one pixel with the same color to maintain consistent behavior.</p>

		<h3>Q4. Explain how you used supersampling to antialias your triangles.</h3>
		<p>By averaging the color from multiple sub-pixel samples, partially-covered pixels at triangle edges get intermediate color values instead of being either fully colored or fully background. This produces smooth gradual transitions at edges rather than hard staircase patterns.</p>

		<h3>Q5. Show png screenshots of basic/test4.svg with sample rates 1, 4, and 16.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_2_sample_rate_1.png" width="400px"/>
				  <figcaption>Sample rate 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_2_sample_rate_4.png" width="400px"/>
				  <figcaption>Sample rate 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;" colspan="2">
				  <img src="./images/write_2_sample_rate_16.png" width="400px"/>
				  <figcaption>Sample rate 16</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>At sample rate 1, the skinny triangle corner has severe aliasing: pixels are either fully colored or fully background, producing a jagged staircase pattern. At sample rate 4, the edges become smoother because each pixel now samples 4 sub-pixel locations; partially-covered pixels receive intermediate colors. At sample rate 16, the edges are even smoother with finer gradation, since 16 samples per pixel can represent finer degrees of partial coverage, producing a nearly continuous transition at triangle boundaries.</p>

		<h3>Extra Credit: Jittered Sampling</h3>
		<p>I implemented jittered sampling, which replaces the fixed 0.5 sub-pixel offset with a random value between 0 and 1 for each sample.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_2_sample_rate_16.png" width="400px"/>
				  <figcaption>Grid-based supersampling (16 spp)</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_2_sample_rate_16_jittered.png" width="400px"/>
				  <figcaption>Jittered sampling (16 spp)</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>Jittered sampling produces slightly different pixel coverage than grid-based supersampling because the random offsets shift sample points across sub-pixel boundaries. This trades the regular aliasing patterns of grid sampling (which can produce visible structured artifacts at certain frequencies) for stochastic noise, which is generally less visually objectionable. At high sample counts the two methods converge, but at lower sample counts jittered sampling better handles cases where regular grid patterns happen to systematically miss or hit triangle edges.</p>

		<h2>Task 3: Transforms</h2>

		<h3>Q1. Create an updated version of cubeman doing something more interesting.</h3>
		<figure>
			<img src="./images/write_3_picture.png" style="width:50%"/>
			<figcaption>I made the cubeman waving using his right hand.</figcaption>
		</figure>

		<h3>Extra Credit: Viewport rotation</h3>
		<p>I added two keys to rotate the viewport left and right.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_3_picture_right_rotate.png" width="300px"/>
				  <figcaption>Right rotation</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_3_picture.png" width="300px"/>
				  <figcaption>Normal</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_3_picture_left_rotate.png" width="300px"/>
				  <figcaption>Left rotation</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>Modification: Added a rotation matrix <code>rotation = translate(0.5, 0.5) * rotate(angle) * translate(-0.5, -0.5)</code> into the matrix stack: <code>ndc_to_screen * rotation * svg_to_ndc[current_svg]</code>. The translation to (0.5, 0.5) and back ensures rotation happens around the center of the NDC space rather than the origin.</p>

		<h2>Task 4: Barycentric coordinates</h2>

		<h3>Q1. Explain barycentric coordinates in your own words.</h3>
		<p>Barycentric coordinates decompose a point into a linear combination of three vertices. Mathematically, given a point P and triangle vertices A, B, C: \( P = \alpha A + \beta B + \gamma C \), where \( \alpha = S_{PBC} / S_{ABC} \), \( \beta = S_{PAC} / S_{ABC} \), \( \gamma = S_{PAB} / S_{ABC} \). Each coefficient represents the relative area of the sub-triangle opposite to the corresponding vertex, normalized by the total triangle area.</p>
		<figure>
			<img src="./images/write_4_picture_triangle.png" style="width:50%"/>
			<figcaption>A single triangle with red, green, and blue vertices. The smooth color blending demonstrates how barycentric coordinates interpolate attributes across the triangle surface.</figcaption>
		</figure>

		<h3>Q2. Show a png screenshot of svg/basic/test7.svg with default viewing parameters and sample rate 1.</h3>
		<figure>
			<img src="./images/write_4_picture_circle.png" style="width:50%"/>
			<figcaption>test7.svg - Color wheel rendered using barycentric coordinate interpolation.</figcaption>
		</figure>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>

		<h3>Q1. Explain pixel sampling and describe how you implemented it for texture mapping.</h3>
		<p>Pixel sampling maps screen-space pixel coordinates to texture coordinates (u, v) to retrieve color values from the texture.</p>
		<p>Implementation:</p>
		<ul>
			<li><b>Nearest:</b> Compute the (u, v) coordinates by interpolating the UV coordinates of the three vertices using barycentric coordinates. Then take the floor of (u, v) to find the nearest texel.</li>
			<li><b>Bilinear:</b> Compute the (u, v) coordinates the same way. Then subtract a (0.5, 0.5) offset and find the 4 surrounding texels. Finally, perform bilinear interpolation of these 4 texels' colors using the fractional offsets as weights.</li>
		</ul>
		<p>Comparison:</p>
		<ul>
			<li><b>Nearest:</b> Cheaper computation (single texel lookup), but produces blocky artifacts and visible jaggies at texture boundaries.</li>
			<li><b>Bilinear:</b> Slightly more expensive (4 texel lookups + 3 lerps), but produces smoother results at the cost of some detail sharpness.</li>
		</ul>

		<h3>Q2. Show and compare four png screenshots using nearest/bilinear sampling at 1 and 16 samples per pixel.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_5_sp_1_nearest.png" width="400px"/>
				  <figcaption>Nearest, 1 spp</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_5_sp_1_bilinear.png" width="400px"/>
				  <figcaption>Bilinear, 1 spp</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_5_sp_16_nearest.png" width="400px"/>
				  <figcaption>Nearest, 16 spp</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_5_sp_16_bilinear.png" width="400px"/>
				  <figcaption>Bilinear, 16 spp</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>At 1 sample per pixel, nearest sampling shows clear blocky artifacts and sharp discontinuities at texel boundaries, while bilinear sampling produces noticeably smoother transitions. At 16 samples per pixel, both methods improve significantly since supersampling itself provides smoothing, but bilinear still shows slightly smoother results. The gap between nearest and bilinear is much larger at 1 spp than at 16 spp, because supersampling partially compensates for nearest sampling's blockiness.</p>

		<h3>Q3. When will there be a large difference between the two methods and why?</h3>
		<p>The largest difference between nearest and bilinear sampling occurs when the texture is magnified (i.e., each texel maps to multiple screen pixels). In this regime, nearest sampling produces visible blocky patches where adjacent screen pixels map to the same texel, creating a "pixelated" look. Bilinear sampling smoothly interpolates between neighboring texels, eliminating these hard boundaries.</p>
		<p>The difference is minimal when: (1) the texture resolution closely matches the screen resolution (1:1 mapping), since both methods sample roughly the same texels; or (2) supersampling rate is very high, which provides enough spatial averaging to mask nearest sampling's artifacts.</p>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>

		<h3>Q1. Explain level sampling in your own words and describe how you implemented it for texture mapping.</h3>
		<p>Level sampling selects an appropriate mipmap level based on the screen-space footprint of a pixel in texture space, then samples the texture from that level. The goal is to match the texel density to the pixel density, avoiding aliasing from undersampling and unnecessary blur from oversampling.</p>
		<p>Implementation:</p>
		<ul>
			<li><b>L_ZERO:</b> Always sample from the full-resolution (level 0) mipmap.</li>
			<li><b>L_NEAREST:</b> Compute the mipmap level as log<sub>2</sub> of the maximum norm of the screen-space derivatives (dx_uv, dy_uv), then round to the nearest integer. Sample from that single mipmap level.</li>
			<li><b>L_LINEAR:</b> Compute the continuous mipmap level the same way, then sample from both the floor and ceiling levels and linearly interpolate between them (trilinear filtering when combined with bilinear pixel sampling).</li>
			<li><b>L_ANISOTROPIC:</b> Compute the mipmap level using the <em>shorter</em> of the two derivatives, so the selected level preserves detail along the minor axis. Then take multiple samples along the longer derivative direction and average them. This avoids the over-blurring that isotropic mipmaps produce at oblique viewing angles.</li>
		</ul>

		<h3>Q2. Describe the tradeoffs between pixel sampling, level sampling, and supersampling.</h3>
		<table class="benchmark">
			<tr><th>Technique</th><th>Speed</th><th>Memory</th><th>Antialiasing Quality</th></tr>
			<tr>
				<td><b>Pixel sampling</b> (nearest vs bilinear)</td>
				<td>Fastest. Nearest requires 1 texel lookup; bilinear requires 4 lookups + 3 lerps. Negligible overhead either way.</td>
				<td>No additional memory beyond the base texture.</td>
				<td>Bilinear smooths magnification artifacts but does not address minification aliasing (multiple texels mapping to one pixel). Limited antialiasing power on its own.</td>
			</tr>
			<tr>
				<td><b>Level sampling</b> (mipmaps)</td>
				<td>Moderate. Requires computing screen-space derivatives per pixel. L_NEAREST adds one extra level lookup; L_LINEAR doubles the pixel sampling cost; anisotropic multiplies it by the anisotropy ratio.</td>
				<td>Mipmaps require ~33% extra memory (sum of 1/4 + 1/16 + ... of the base texture).</td>
				<td>Effectively handles minification aliasing by pre-filtering the texture at multiple scales. Combined with bilinear pixel sampling (trilinear), produces smooth results across varying texture densities.</td>
			</tr>
			<tr>
				<td><b>Supersampling</b></td>
				<td>Slowest. Cost scales linearly with sample rate: 16 spp is 16x the work of 1 spp, including both rasterization and texture lookups.</td>
				<td>Sample buffer scales linearly with sample rate: 16 spp requires 16x the framebuffer memory.</td>
				<td>Most general: reduces aliasing from all sources (geometry edges, texture, shading). But brute-force and expensive for the quality gained compared to targeted techniques.</td>
			</tr>
		</table>
		<p>In practice, the best quality-to-cost ratio comes from combining bilinear pixel sampling with mipmap level sampling (trilinear filtering), supplemented by moderate supersampling (e.g., 4 spp) for geometry edge antialiasing.</p>

		<h3>Q3. Show four versions of an image using combinations of L_ZERO/L_NEAREST and P_NEAREST/P_LINEAR.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_6_l_zero_p_nearest.png" width="400px"/>
				  <figcaption>L_ZERO, P_NEAREST</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_6_l_zero_p_bilinear.png" width="400px"/>
				  <figcaption>L_ZERO, P_BILINEAR</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="./images/write_6_l_nearest_p_nearest.png" width="400px"/>
				  <figcaption>L_NEAREST, P_NEAREST</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="./images/write_6_l_nearest_p_bilinear.png" width="400px"/>
				  <figcaption>L_NEAREST, P_BILINEAR</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h3>Extra Credit: Anisotropic Filtering</h3>
		<p>I implemented anisotropic filtering: the mipmap level is computed using the shorter of the two screen-space derivatives (dx_uv, dy_uv), preserving detail along the minor axis. Then, multiple samples are taken along the longer derivative direction at that mipmap level and averaged. This prevents the over-blurring that standard isotropic mipmaps produce when surfaces are viewed at oblique angles, because the filtering shape matches the elongated pixel footprint in texture space rather than approximating it as a square.</p>

		<h2>Extra Credit: Draw Something Creative</h2>
		<figure>
			<img src="./images/competition.png" style="width:70%"/>
			<figcaption>Generated using a quadtree-based SVG generation script (src/generate_svg.cpp) that converts a PNG image into SVG triangles.</figcaption>
		</figure>

		</div>
	</body>
</html>
