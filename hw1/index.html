<html>
  <head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <style>
      h1 {
        text-align: center;
      }

      .container {
        margin: 0 auto;
        padding: 60px 20%;
      }

      figure {
        text-align: center;
      }

      img {
        display: inline-block;
        max-width: 100%;
      }

      body {
        font-family: "Inter", sans-serif;
        line-height: 1.6;
      }

      table {
        border-collapse: collapse;
        width: 100%;
        margin: 10px 0;
      }

      table.benchmark td,
      table.benchmark th {
        border: 1px solid #ddd;
        padding: 6px 10px;
        text-align: left;
      }

      table.benchmark th {
        background-color: #f5f5f5;
      }

      code {
        background-color: #f4f4f4;
        padding: 2px 5px;
        border-radius: 3px;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>CS184/284A Spring 2026 Homework 1 Write-Up</h1>
      <div style="text-align: center">Name: Haoyi Yu</div>

      <br />

      Link to webpage:
      <a href="https://cal-cs184-student.github.io/hw-webpages-Asnly1/"
        >cs184.eecs.berkeley.edu/sp25</a
      >

      <br />

      Link to GitHub repository:
      <a href="https://cs184.eecs.berkeley.edu/sp25"
        >cs184.eecs.berkeley.edu/sp25</a
      >

      <h2>Overview</h2>
      <p>
        In this project, I implemented a rasterizer that supports triangle
        rasterization, supersampling-based antialiasing, 2D transforms,
        barycentric coordinate interpolation, texture mapping with pixel
        sampling and level sampling (mipmaps), and anisotropic filtering.
      </p>
      <p>Key takeaways:</p>
      <ul>
        <li>
          Rasterization performance is heavily influenced by memory access
          patterns. Seemingly obvious optimizations (like pre-calculating
          constants or changing loop order) can actually hurt performance due to
          cache effects. Tiled traversal with tile size 8 achieved the best
          speedup (~1.8x over naive) by balancing computation savings with
          cache-friendly access.
        </li>
        <li>
          Antialiasing is fundamentally about trading computation/memory for
          visual quality. Supersampling is conceptually the simplest but most
          expensive; pixel-level bilinear sampling and mipmap-based level
          sampling offer better cost-quality tradeoffs.
        </li>
        <li>
          Anisotropic filtering addresses a real limitation of isotropic
          mipmaps: when a surface is viewed at an oblique angle, the footprint
          in texture space is elongated, and standard mipmaps over-blur in one
          direction. Sampling along the major axis at a finer mipmap level
          preserves detail where it matters.
        </li>
      </ul>

      <h2>Task 1: Drawing Single-Color Triangles</h2>

      <h3>Q1. Walk through how you rasterize triangles in your own words.</h3>
      <ul>
        <li>
          Ensure counterclockwise winding by checking the cross product of edge
          vectors; swap vertices if needed.
        </li>
        <li>Compute the bounding box and clamp it to screen bounds.</li>
        <li>
          Iterate over 8&times;8 tiles within the bounding box. Test each tile
          against the triangle: if fully inside, rasterize all pixels without
          per-pixel edge tests; if fully outside, skip entirely; otherwise, test
          each pixel individually.
        </li>
        <li>
          For each candidate pixel, sample at its center (+0.5, +0.5 offset) and
          evaluate three edge functions. A pixel is filled if it passes all
          three tests, using OpenGL top-left edge rules for tie-breaking.
        </li>
      </ul>

      <h3>
        Q2. Explain how your algorithm is no worse than one that checks each
        sample within the bounding box of the triangle.
      </h3>
      <ul>
        <li>
          First, I test a tile of pixels first. If the tile is fully
          inside/outside of the triangle, then skip the test of pixels in the
          tile. If not the case, test each pixel in the tile explicitly. Using
          the tiled triangle traversal, I decrease the computation.
        </li>
        <li>
          Second, instead of testing pixels independently, I test pixels based
          on previous result: by utilizing the linear feature of line function,
          I degenerate the expensive multiplication into cheap addition.
        </li>
      </ul>

      <h3>
        Q3. Show a png screenshot of basic/test4.svg with the default viewing
        parameters and with the pixel inspector centered on an interesting part
        of the scene.
      </h3>
      <figure>
        <img src="./images/write_1_picture.png" style="width: 70%" />
        <figcaption>
          test4.svg - This part shows explicitly jaggies in the sharp edge of
          the purple triangle.
        </figcaption>
      </figure>

      <h3>
        Extra Credit: Special optimizations beyond simple bounding box triangle
        rasterization
      </h3>
      <p>
        The following statistic is based on running for 200 times and the first
        100 results are excluded to fully warm up the cache.
      </p>
      <table class="benchmark">
        <tr>
          <th>Version</th>
          <th>Mean (ms)</th>
          <th>Std (ms)</th>
          <th>Notes</th>
        </tr>
        <tr>
          <td>V1: Naive</td>
          <td>0.979</td>
          <td>0.029</td>
          <td>Baseline</td>
        </tr>
        <tr>
          <td>V2: Pre-calculate constants</td>
          <td>1.037</td>
          <td>0.025</td>
          <td>Slower: compiler already did this; extra variables hurt cache</td>
        </tr>
        <tr>
          <td>V3: Exchange loop order (y-x)</td>
          <td>1.219</td>
          <td>0.025</td>
          <td>Slower: original x-y order fits cache line better</td>
        </tr>
        <tr>
          <td>V4: Incremental traversal</td>
          <td>0.801</td>
          <td>0.024</td>
          <td>
            Use addition instead of multiplication via linear property of edge
            functions
          </td>
        </tr>
        <tr>
          <td>V5: Tiled (tile=2)</td>
          <td>1.238</td>
          <td>0.048</td>
          <td>Too small tile, overhead dominates</td>
        </tr>
        <tr>
          <td>V5: Tiled (tile=4)</td>
          <td>0.643</td>
          <td>0.034</td>
          <td></td>
        </tr>
        <tr>
          <td>V5: Tiled (tile=8)</td>
          <td>0.545</td>
          <td>0.034</td>
          <td>Best: ~1.8x speedup over naive</td>
        </tr>
        <tr>
          <td>V5: Tiled (tile=16)</td>
          <td>0.640</td>
          <td>0.038</td>
          <td></td>
        </tr>
        <tr>
          <td>V5: Tiled (tile=32)</td>
          <td>0.934</td>
          <td>0.030</td>
          <td>Larger tiles reduce benefit of skipping</td>
        </tr>
      </table>
      <p>
        <b>Tiled traversal (tile=8):</b> First test a block of pixels. If the
        block is fully inside the triangle, simply rasterize all pixels without
        per-pixel edge tests. If the block is fully outside the triangle, skip
        it entirely. Otherwise, fall back to incremental traversal within the
        block.
      </p>
      <p>
        <b>Why some "optimizations" slow down:</b> Pre-calculating constants and
        exchanging loop order both hurt cache hit rate. The compiler already
        performs constant folding, and x-major loop order naturally aligns with
        row-major memory layout.
      </p>

      <h2>Task 2: Antialiasing by Supersampling</h2>

      <h3>
        Q1. Walk through your supersampling algorithm and data structures.
      </h3>
      <ul>
        <li>
          Step 1: Divide one original pixel into sqrt(sample_rate) &times;
          sqrt(sample_rate) subpixels.
        </li>
        <li>
          Step 2: Evaluate each subpixel as a normal pixel to decide whether or
          not to rasterize it.
        </li>
        <li>
          Step 3: Write the rasterize results of subpixels into the sample
          buffer.
        </li>
        <li>
          Step 4: Sum up the colors of all subpixels belonging to one pixel then
          divide by sample rate to get the final color.
        </li>
      </ul>

      <h3>Q2. Why is supersampling useful?</h3>
      <p>
        It takes the average of color across multiple sub-pixel samples within
        one pixel, which smooths out jagged edges (aliasing artifacts) along
        triangle boundaries.
      </p>

      <h3>
        Q3. What modifications did you make to the rasterization pipeline in the
        process?
      </h3>
      <p>
        For triangles: evaluate subpixels then take the average color of
        subpixels, as described in Q1.
      </p>
      <p>
        For points and lines: fill up all subpixels in one pixel with the same
        color to maintain consistent behavior.
      </p>

      <h3>
        Q4. Explain how you used supersampling to antialias your triangles.
      </h3>
      <p>
        By averaging the color from multiple sub-pixel samples,
        partially-covered pixels at triangle edges get intermediate color values
        instead of being either fully colored or fully background. This produces
        smooth gradual transitions at edges rather than hard staircase patterns.
      </p>

      <h3>
        Q5. Show png screenshots of basic/test4.svg with sample rates 1, 4, and
        16.
      </h3>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 100%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="./images/write_2_sample_rate_1.png" width="400px" />
              <figcaption>Sample rate 1</figcaption>
            </td>
            <td style="text-align: center">
              <img src="./images/write_2_sample_rate_4.png" width="400px" />
              <figcaption>Sample rate 4</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center" colspan="2">
              <img src="./images/write_2_sample_rate_16.png" width="400px" />
              <figcaption>Sample rate 16</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <p>
        At 1 spp, the skinny triangle corner exhibits severe jaggies: pixels are
        binary (fully colored or background). At 4 spp, partially-covered pixels
        receive intermediate colors, visibly smoothing edges. At 16 spp, the
        finer sub-pixel resolution captures even subtler degrees of coverage,
        producing nearly continuous transitions at triangle boundaries.
      </p>

      <h3>Extra Credit: Jittered Sampling</h3>
      <p>
        I implemented jittered sampling, which replaces the fixed 0.5 sub-pixel
        offset with a random value between 0 and 1 for each sample.
      </p>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 100%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="./images/write_2_sample_rate_16.png" width="400px" />
              <figcaption>Grid-based supersampling (16 spp)</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="./images/write_2_sample_rate_16_jittered.png"
                width="400px"
              />
              <figcaption>Jittered sampling (16 spp)</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <p>
        Jittered sampling replaces grid sampling's regular aliasing patterns
        (which can produce structured artifacts at certain frequencies) with
        stochastic noise, which is generally less visually objectionable. At
        high sample counts the two methods converge, but at lower counts
        jittered sampling avoids the systematic miss/hit patterns that regular
        grids can exhibit along triangle edges.
      </p>

      <h2>Task 3: Transforms</h2>

      <h3>
        Q1. Create an updated version of cubeman doing something more
        interesting.
      </h3>
      <figure>
        <img src="./images/write_3_picture.png" style="width: 50%" />
        <figcaption>I made the cubeman waving using his right hand.</figcaption>
      </figure>

      <h3>Extra Credit: Viewport rotation</h3>
      <p>I added two keys to rotate the viewport left and right.</p>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 100%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img
                src="./images/write_3_picture_right_rotate.png"
                width="300px"
              />
              <figcaption>Right rotation</figcaption>
            </td>
            <td style="text-align: center">
              <img src="./images/write_3_picture.png" width="300px" />
              <figcaption>Normal</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="./images/write_3_picture_left_rotate.png"
                width="300px"
              />
              <figcaption>Left rotation</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <p>
        Modification: Added a rotation matrix
        <code
          >rotation = translate(0.5, 0.5) * rotate(angle) * translate(-0.5,
          -0.5)</code
        >
        into the matrix stack:
        <code>ndc_to_screen * rotation * svg_to_ndc[current_svg]</code>. The
        translation to (0.5, 0.5) and back ensures rotation happens around the
        center of the NDC space rather than the origin.
      </p>

      <h2>Task 4: Barycentric coordinates</h2>

      <h3>Q1. Explain barycentric coordinates in your own words.</h3>
      <p>
        Barycentric coordinates decompose a point into a linear combination of
        three vertices. Mathematically, given a point P and triangle vertices A,
        B, C: \( P = \alpha A + \beta B + \gamma C \), where \( \alpha = S_{PBC}
        / S_{ABC} \), \( \beta = S_{PAC} / S_{ABC} \), \( \gamma = S_{PAB} /
        S_{ABC} \). Each coefficient represents the relative area of the
        sub-triangle opposite to the corresponding vertex, normalized by the
        total triangle area.
      </p>
      <figure>
        <img src="./images/write_4_picture_triangle.png" style="width: 50%" />
        <figcaption>
          A single triangle with red, green, and blue vertices. The smooth color
          blending demonstrates how barycentric coordinates interpolate
          attributes across the triangle surface.
        </figcaption>
      </figure>

      <h3>
        Q2. Show a png screenshot of svg/basic/test7.svg with default viewing
        parameters and sample rate 1.
      </h3>
      <figure>
        <img src="./images/write_4_picture_circle.png" style="width: 50%" />
        <figcaption>
          test7.svg - Color wheel rendered using barycentric coordinate
          interpolation.
        </figcaption>
      </figure>

      <h2>Task 5: "Pixel sampling" for texture mapping</h2>

      <h3>
        Q1. Explain pixel sampling and describe how you implemented it for
        texture mapping.
      </h3>
      <p>
        Pixel sampling maps screen-space pixel coordinates to texture
        coordinates (u, v) to retrieve color values from the texture.
      </p>
      <p>Implementation:</p>
      <ul>
        <li>
          <b>Nearest:</b> Compute the (u, v) coordinates by interpolating the UV
          coordinates of the three vertices using barycentric coordinates. Then
          take the floor of (u, v) to find the nearest texel.
        </li>
        <li>
          <b>Bilinear:</b> Compute the (u, v) coordinates the same way. Then
          subtract a (0.5, 0.5) offset and find the 4 surrounding texels.
          Finally, perform bilinear interpolation of these 4 texels' colors
          using the fractional offsets as weights.
        </li>
      </ul>
      <p>Comparison:</p>
      <ul>
        <li>
          <b>Nearest:</b> Cheaper computation (single texel lookup), but
          produces blocky artifacts and visible jaggies at texture boundaries.
        </li>
        <li>
          <b>Bilinear:</b> Slightly more expensive (4 texel lookups + 3 lerps),
          but produces smoother results at the cost of some detail sharpness.
        </li>
      </ul>

      <h3>
        Q2. Show and compare four png screenshots using nearest/bilinear
        sampling at 1 and 16 samples per pixel.
      </h3>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 100%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="./images/write_5_sp_1_nearest.png" width="400px" />
              <figcaption>Nearest, 1 spp</figcaption>
            </td>
            <td style="text-align: center">
              <img src="./images/write_5_sp_1_bilinear.png" width="400px" />
              <figcaption>Bilinear, 1 spp</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img src="./images/write_5_sp_16_nearest.png" width="400px" />
              <figcaption>Nearest, 16 spp</figcaption>
            </td>
            <td style="text-align: center">
              <img src="./images/write_5_sp_16_bilinear.png" width="400px" />
              <figcaption>Bilinear, 16 spp</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <p>
        At 1 sample per pixel, nearest sampling shows clear blocky artifacts and
        sharp discontinuities at texel boundaries, while bilinear sampling
        produces noticeably smoother transitions. At 16 samples per pixel, both
        methods improve significantly since supersampling itself provides
        smoothing, but bilinear still shows slightly smoother results. The gap
        between nearest and bilinear is much larger at 1 spp than at 16 spp,
        because supersampling partially compensates for nearest sampling's
        blockiness.
      </p>

      <h3>
        Q3. When will there be a large difference between the two methods and
        why?
      </h3>
      <p>
        The gap is largest during texture magnification (each texel maps to
        multiple screen pixels): nearest sampling produces blocky patches while
        bilinear smoothly interpolates between texels. The difference is minimal
        when texture and screen resolutions are closely matched (1:1 mapping),
        or when a high supersampling rate provides enough spatial averaging to
        mask nearest sampling's artifacts.
      </p>

      <h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>

      <h3>
        Q1. Explain level sampling in your own words and describe how you
        implemented it for texture mapping.
      </h3>
      <p>
        Level sampling selects an appropriate mipmap level based on the
        screen-space footprint of a pixel in texture space, then samples the
        texture from that level. The goal is to match the texel density to the
        pixel density, avoiding aliasing from undersampling and unnecessary blur
        from oversampling.
      </p>
      <p>Implementation:</p>
      <ul>
        <li>
          <b>L_ZERO:</b> Always sample from the full-resolution (level 0)
          mipmap.
        </li>
        <li>
          <b>L_NEAREST:</b> Compute the mipmap level as log<sub>2</sub> of the
          maximum norm of the screen-space derivatives (dx_uv, dy_uv), then
          round to the nearest integer. Sample from that single mipmap level.
        </li>
        <li>
          <b>L_LINEAR:</b> Compute the continuous mipmap level the same way,
          then sample from both the floor and ceiling levels and linearly
          interpolate between them (trilinear filtering when combined with
          bilinear pixel sampling).
        </li>
        <li>
          <b>L_ANISOTROPIC:</b> Compute the mipmap level using the
          <em>shorter</em> of the two derivatives, so the selected level
          preserves detail along the minor axis. Then take multiple samples
          along the longer derivative direction and average them. This avoids
          the over-blurring that isotropic mipmaps produce at oblique viewing
          angles.
        </li>
      </ul>

      <h3>
        Q2. Describe the tradeoffs between pixel sampling, level sampling, and
        supersampling.
      </h3>
      <table class="benchmark">
        <tr>
          <th>Technique</th>
          <th>Speed</th>
          <th>Memory</th>
          <th>Antialiasing Quality</th>
        </tr>
        <tr>
          <td><b>Pixel sampling</b> (nearest vs bilinear)</td>
          <td>
            Fastest. Nearest requires 1 texel lookup; bilinear requires 4
            lookups + 3 lerps. Negligible overhead either way.
          </td>
          <td>No additional memory beyond the base texture.</td>
          <td>
            Bilinear smooths magnification artifacts but does not address
            minification aliasing (multiple texels mapping to one pixel).
            Limited antialiasing power on its own.
          </td>
        </tr>
        <tr>
          <td><b>Level sampling</b> (mipmaps)</td>
          <td>
            Moderate. Requires computing screen-space derivatives per pixel.
            L_NEAREST adds one extra level lookup; L_LINEAR doubles the pixel
            sampling cost; anisotropic multiplies it by the anisotropy ratio.
          </td>
          <td>
            Mipmaps require ~33% extra memory (sum of 1/4 + 1/16 + ... of the
            base texture).
          </td>
          <td>
            Effectively handles minification aliasing by pre-filtering the
            texture at multiple scales. Combined with bilinear pixel sampling
            (trilinear), produces smooth results across varying texture
            densities.
          </td>
        </tr>
        <tr>
          <td><b>Supersampling</b></td>
          <td>
            Slowest. Cost scales linearly with sample rate: 16 spp is 16x the
            work of 1 spp, including both rasterization and texture lookups.
          </td>
          <td>
            Sample buffer scales linearly with sample rate: 16 spp requires 16x
            the framebuffer memory.
          </td>
          <td>
            Most general: reduces aliasing from all sources (geometry edges,
            texture, shading). But brute-force and expensive for the quality
            gained compared to targeted techniques.
          </td>
        </tr>
      </table>
      <p>
        In practice, the best quality-to-cost ratio comes from combining
        bilinear pixel sampling with mipmap level sampling (trilinear
        filtering), supplemented by moderate supersampling (e.g., 4 spp) for
        geometry edge antialiasing.
      </p>

      <h3>
        Q3. Show four versions of an image using combinations of
        L_ZERO/L_NEAREST and P_NEAREST/P_LINEAR.
      </h3>
      <div style="display: flex; flex-direction: column; align-items: center">
        <table
          style="width: 100%; text-align: center; border-collapse: collapse"
        >
          <tr>
            <td style="text-align: center">
              <img src="./images/write_6_l_zero_p_nearest.png" width="400px" />
              <figcaption>L_ZERO, P_NEAREST</figcaption>
            </td>
            <td style="text-align: center">
              <img src="./images/write_6_l_zero_p_bilinear.png" width="400px" />
              <figcaption>L_ZERO, P_BILINEAR</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center">
              <img
                src="./images/write_6_l_nearest_p_nearest.png"
                width="400px"
              />
              <figcaption>L_NEAREST, P_NEAREST</figcaption>
            </td>
            <td style="text-align: center">
              <img
                src="./images/write_6_l_nearest_p_bilinear.png"
                width="400px"
              />
              <figcaption>L_NEAREST, P_BILINEAR</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <h3>Extra Credit: Anisotropic Filtering</h3>
      <p>
        I implemented anisotropic filtering: the mipmap level is computed using
        the shorter of the two screen-space derivatives (dx_uv, dy_uv),
        preserving detail along the minor axis. Then, multiple samples are taken
        along the longer derivative direction at that mipmap level and averaged.
        This prevents the over-blurring that standard isotropic mipmaps produce
        when surfaces are viewed at oblique angles, because the filtering shape
        matches the elongated pixel footprint in texture space rather than
        approximating it as a square.
      </p>

      <h2>Extra Credit: Draw Something Creative</h2>
      <figure>
        <img src="./images/competition.png" style="width: 70%" />
        <figcaption>
          Generated using an adaptive quadtree-based SVG generation script
          (<code>src/generate_svg.cpp</code>) that converts a PNG image into
          color-interpolated SVG triangles.
        </figcaption>
      </figure>

      <h3>Algorithm Overview</h3>
      <p>
        The core idea is to adaptively partition the image into axis-aligned
        rectangles using a quadtree, then split each rectangle along a diagonal
        into two color-interpolated triangles. Regions with more visual
        complexity receive finer subdivision, preserving detail where it matters
        while using fewer triangles in smooth areas.
      </p>

      <h3>Key Techniques</h3>
      <ul>
        <li>
          <b>Canny edge-guided subdivision priority:</b> A Canny edge detector
          identifies high-frequency regions in the image. The edge map is
          incorporated into the subdivision error metric via an integral image,
          so rectangles containing more edge pixels are prioritized for
          splitting. This concentrates triangles along object boundaries and
          fine details.
        </li>
        <li>
          <b>Integral images for O(1) error computation:</b> Precomputed
          integral images (both sum and sum-of-squares) for each color channel
          enable constant-time SSE (sum of squared errors) queries over any
          axis-aligned rectangle. The SSE measures color variance within a
          region: \( \text{SSE} = \sum x_i^2 - (\sum x_i)^2 / n \). High SSE
          indicates the region is too complex to represent with a single color
          gradient and should be subdivided.
        </li>
        <li>
          <b>Max-heap priority queue:</b> All candidate rectangles are stored in
          a max-heap ordered by their error metric. At each step, the rectangle
          with the highest error is popped and split into four children. This
          greedy strategy ensures the triangle budget is spent on the regions
          that benefit most from subdivision.
        </li>
        <li>
          <b>Adaptive diagonal selection:</b> Each rectangle is split into two
          triangles along one of its diagonals. The algorithm compares the color
          difference between the two pairs of opposite corners (TL-BR vs TR-BL)
          and chooses the diagonal whose endpoints are more similar in color.
          This reduces visible seams along the diagonal edge.
        </li>
        <li>
          <b>Vertex color averaging:</b> Instead of sampling a single pixel at
          each corner, vertex colors are computed as the average over a small
          local window (3&times;3) using the integral images. This smooths out
          noise and produces more natural color transitions between adjacent
          triangles.
        </li>
      </ul>
    </div>
  </body>
</html>
